{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTS from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from databaker.framework import *\n",
    "from pathlib import Path\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_perc(x):\n",
    "\n",
    "        if x.strip(' ') == '':\n",
    "            return 'NA'\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_perc2(x):\n",
    "\n",
    "        if x.strip(' ') == 'A':\n",
    "            return 'Asia and Oceania'\n",
    "        elif x.strip(' ') == 'B':  \n",
    "            return 'Eastern Europe'\n",
    "        elif x.strip(' ') == 'C':  \n",
    "            return 'European Union'\n",
    "        elif x.strip(' ') == 'D':  \n",
    "            return 'Latin America and the Caribbean'\n",
    "        elif x.strip(' ') == 'E':  \n",
    "            return 'Low Value Trade (Non-EU)'\n",
    "        elif x.strip(' ') == 'F':  \n",
    "            return 'Middle East and North Africa'\n",
    "        elif x.strip(' ') == 'G':  \n",
    "            return 'North America'\n",
    "        elif x.strip(' ') == 'H':  \n",
    "            return 'Sub-Saharan Africa'\n",
    "        elif x.strip(' ') == 'I':  \n",
    "            return 'Western Europe'\n",
    "        elif x.strip(' ') == 'J':  \n",
    "            return 'Ships and Stores(Non-EU)'\n",
    "        else:  \n",
    "            return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from cachecontrol import CacheControl\n",
    "from cachecontrol.caches.file_cache import FileCache\n",
    "from cachecontrol.heuristics import LastModified\n",
    "from io import BytesIO\n",
    "\n",
    "session = CacheControl(requests.Session(),\n",
    "                       cache=FileCache('.cache'),\n",
    "                       heuristic=LastModified())\n",
    "\n",
    "google_id = [f'https://drive.google.com/uc?export=download&id=1gJDwtdg1NJ9ybtlHmgsIklkhThaBqVJX',\n",
    "            f'https://drive.google.com/uc?export=download&id=1cvel3cvNAwbdN6l1nVfBOwNyfj0Ken2g',\n",
    "            f'https://drive.google.com/uc?export=download&id=1945hQ8L9-NwZMX6B4zZcshJBORcXVZuy',\n",
    "            f'https://drive.google.com/uc?export=download&id=1y8SRiOxyDlMJmuWMmV005VoxUpk0na1l',\n",
    "            f'https://drive.google.com/uc?export=download&id=1ZHJ6lRUHonVLlALeplnMfvdEhgVedtp5',\n",
    "            f'https://drive.google.com/uc?export=download&id=1y7aA8oGo__4YErK09KHZGaRGs79_lauE',\n",
    "            f'https://drive.google.com/uc?export=download&id=1FfApFvt72ogPkhhJfxevR3Fd_otGS-Es',\n",
    "            f'https://drive.google.com/uc?export=download&id=1mZmI8nprCCPwl1kaBhT3dCCC-FXk0CMo']\n",
    "\n",
    "Final_table = pd.DataFrame()\n",
    "for g_id in google_id:\n",
    "    \n",
    "    input_file = BytesIO(session.get(g_id).content)\n",
    "    new_table = pd.read_csv(input_file, delim_whitespace= True, header = None)\n",
    "    new_table_data = new_table[new_table[3].isnull() == False]\n",
    "    new_table = new_table[new_table[3].isnull() == True]\n",
    "    new_table_data[1] =new_table_data[2]\n",
    "    new_table_data[2] =new_table_data[3]\n",
    "    new_table = pd.concat([new_table, new_table_data])\n",
    "    new_table.drop([3], axis =1, inplace =True)\n",
    "    new_table['Period'] =\"quarter/\"+ new_table[0].astype(str).str[2:6]+'-'+new_table[0].astype(str).str[0:2].str[::-1]\n",
    "    new_table['Flow'] = new_table[0].astype(str).str[6:7]\n",
    "    new_table['HMRC Reporter Region'] = new_table[0].astype(str).str[7:9]\n",
    "    new_table['Geography'] = new_table[0].astype(str).str[9:10]\n",
    "    new_table['Codeseq'] = new_table[0].astype(str).str[10:13]\n",
    "    new_table['HMRC Partner Geography'] = new_table[0].astype(str).str[13:15]\n",
    "    new_table['SITC Section'] = new_table[0].astype(str).str[15:16]\n",
    "    new_table['SITC Division'] = new_table[0].astype(str).str[16:18]\n",
    "    new_table.rename(index = str, columns = {2:'Mass'}, inplace = True)\n",
    "    new_table.rename(index = str, columns = {1:'Value'}, inplace = True)\n",
    "    new_table['Unit'] = 'Â£ (thousands)'\n",
    "    new_table['Measure Type'] = 'GBP Total'   \n",
    "    new_table['Geography'] = new_table.apply(lambda row: user_perc2(row['Geography']), axis = 1)\n",
    "    new_table['Flow'] = new_table['Flow'].map(lambda cell:cell.replace('E', 'Exports'))\n",
    "    new_table['Flow'] = new_table['Flow'].map(lambda cell:cell.replace('I', 'Imports'))    \n",
    "    new_table['HMRC Partner Geography'] = new_table.apply(lambda row: user_perc(row['HMRC Partner Geography']), axis = 1)\n",
    "    new_table['SITC Section'] = new_table.apply(lambda row: user_perc(row['SITC Section']), axis = 1)\n",
    "    new_table['SITC Division'] = new_table.apply(lambda row: user_perc(row['SITC Division']), axis = 1)\n",
    "    new_table['SITC 4'] = new_table['SITC Division']  \n",
    "    new_table['Value'] = new_table['Value'].astype('int', copy=False)\n",
    "    new_table = new_table[new_table['Value'] != 0 ]\n",
    "    new_table = new_table[new_table['SITC 4'] != 'NA' ]\n",
    "    new_table['SITC 4'] = new_table['SITC 4'].map(lambda cell: cell.replace('98', '098'))\n",
    "    new_table =new_table[['Period','HMRC Reporter Region','HMRC Partner Geography','SITC 4','Flow','Measure Type','Value','Unit']]\n",
    "    \n",
    "    destinationFolder = Path('out')\n",
    "    destinationFolder.mkdir(exist_ok=True, parents=True)\n",
    "    Final_table = pd.concat([Final_table, new_table])\n",
    "# Final_table.to_csv(destinationFolder / ('rts_Value_tidydata.csv'), index = False) \n",
    "# Final_table.sample(n=10000, random_state=145).to_csv(destinationFolder / ('rts_Value_tidydata.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sliceSize = 10000\n",
    "for i in np.arange(len(Final_table)//sliceSize):\n",
    "    destFile = destinationFolder / f'rts_Value_{i:04}.csv'\n",
    "    Final_table.iloc[i*sliceSize:i*sliceSize+sliceSize-1].to_csv(destFile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
